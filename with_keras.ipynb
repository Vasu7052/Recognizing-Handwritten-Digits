{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from keras.layers import Dropout\n",
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 1)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "digits.keys()\n",
    "images_data = digits['data']\n",
    "image_output = digits['target'].reshape((len(images_data),1))\n",
    "image_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1078, 64)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(images_data,image_output,test_size=0.4 , random_state=0)\n",
    "x_temp_test = x_test\n",
    "y_temp_test = y_test\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.34249754, -1.07638305, ..., -0.25911678,\n",
       "        -0.48330553, -0.17299298],\n",
       "       [ 0.        ,  2.79528442,  1.00457271, ..., -0.77353277,\n",
       "        -0.48330553, -0.17299298],\n",
       "       [ 0.        , -0.34249754,  0.1721904 , ...,  0.25529922,\n",
       "        -0.48330553, -0.17299298],\n",
       "       ..., \n",
       "       [ 0.        , -0.34249754, -0.03590517, ..., -1.11647677,\n",
       "        -0.48330553, -0.17299298],\n",
       "       [ 0.        , -0.34249754, -0.24400075, ..., -1.11647677,\n",
       "        -0.48330553, -0.17299298],\n",
       "       [ 0.        , -0.34249754,  0.1721904 , ...,  0.76971522,\n",
       "        -0.48330553, -0.17299298]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1078, 10)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features=[0])\n",
    "y_train=onehotencoder.fit_transform(y_train).toarray()\n",
    "y_test=onehotencoder.fit_transform(y_test).toarray()\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 2.3024 - acc: 0.1521\n",
      "Epoch 2/100\n",
      "1078/1078 [==============================] - 0s 32us/step - loss: 2.3012 - acc: 0.2143\n",
      "Epoch 3/100\n",
      "1078/1078 [==============================] - 0s 33us/step - loss: 2.2981 - acc: 0.2430\n",
      "Epoch 4/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 2.2892 - acc: 0.2996\n",
      "Epoch 5/100\n",
      "1078/1078 [==============================] - 0s 35us/step - loss: 2.2662 - acc: 0.3061\n",
      "Epoch 6/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 2.2144 - acc: 0.3071\n",
      "Epoch 7/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 2.1264 - acc: 0.3080\n",
      "Epoch 8/100\n",
      "1078/1078 [==============================] - 0s 32us/step - loss: 1.9860 - acc: 0.3098\n",
      "Epoch 9/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 1.8332 - acc: 0.3275\n",
      "Epoch 10/100\n",
      "1078/1078 [==============================] - 0s 36us/step - loss: 1.6850 - acc: 0.3636\n",
      "Epoch 11/100\n",
      "1078/1078 [==============================] - 0s 41us/step - loss: 1.5351 - acc: 0.4017\n",
      "Epoch 12/100\n",
      "1078/1078 [==============================] - 0s 36us/step - loss: 1.4036 - acc: 0.4592\n",
      "Epoch 13/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 1.2731 - acc: 0.5093\n",
      "Epoch 14/100\n",
      "1078/1078 [==============================] - 0s 34us/step - loss: 1.1887 - acc: 0.5380\n",
      "Epoch 15/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 1.0935 - acc: 0.5974\n",
      "Epoch 16/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 1.0126 - acc: 0.6373\n",
      "Epoch 17/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.9253 - acc: 0.6744\n",
      "Epoch 18/100\n",
      "1078/1078 [==============================] - 0s 33us/step - loss: 0.8754 - acc: 0.6939\n",
      "Epoch 19/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.8193 - acc: 0.7106\n",
      "Epoch 20/100\n",
      "1078/1078 [==============================] - 0s 34us/step - loss: 0.7851 - acc: 0.7236\n",
      "Epoch 21/100\n",
      "1078/1078 [==============================] - 0s 35us/step - loss: 0.7377 - acc: 0.7328\n",
      "Epoch 22/100\n",
      "1078/1078 [==============================] - 0s 45us/step - loss: 0.7010 - acc: 0.7430\n",
      "Epoch 23/100\n",
      "1078/1078 [==============================] - 0s 42us/step - loss: 0.6917 - acc: 0.7570\n",
      "Epoch 24/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 0.6722 - acc: 0.7542\n",
      "Epoch 25/100\n",
      "1078/1078 [==============================] - 0s 43us/step - loss: 0.6444 - acc: 0.7616\n",
      "Epoch 26/100\n",
      "1078/1078 [==============================] - 0s 41us/step - loss: 0.6212 - acc: 0.7699\n",
      "Epoch 27/100\n",
      "1078/1078 [==============================] - 0s 38us/step - loss: 0.6203 - acc: 0.7709\n",
      "Epoch 28/100\n",
      "1078/1078 [==============================] - 0s 45us/step - loss: 0.5880 - acc: 0.7839\n",
      "Epoch 29/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 0.5658 - acc: 0.7857\n",
      "Epoch 30/100\n",
      "1078/1078 [==============================] - 0s 41us/step - loss: 0.5467 - acc: 0.7959\n",
      "Epoch 31/100\n",
      "1078/1078 [==============================] - 0s 43us/step - loss: 0.5385 - acc: 0.7996\n",
      "Epoch 32/100\n",
      "1078/1078 [==============================] - 0s 43us/step - loss: 0.5308 - acc: 0.8024\n",
      "Epoch 33/100\n",
      "1078/1078 [==============================] - 0s 41us/step - loss: 0.4924 - acc: 0.8173\n",
      "Epoch 34/100\n",
      "1078/1078 [==============================] - 0s 40us/step - loss: 0.4726 - acc: 0.8191\n",
      "Epoch 35/100\n",
      "1078/1078 [==============================] - 0s 44us/step - loss: 0.4706 - acc: 0.8117\n",
      "Epoch 36/100\n",
      "1078/1078 [==============================] - 0s 42us/step - loss: 0.4605 - acc: 0.8275\n",
      "Epoch 37/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 0.4537 - acc: 0.8358\n",
      "Epoch 38/100\n",
      "1078/1078 [==============================] - 0s 38us/step - loss: 0.4363 - acc: 0.8534\n",
      "Epoch 39/100\n",
      "1078/1078 [==============================] - 0s 38us/step - loss: 0.4356 - acc: 0.8488\n",
      "Epoch 40/100\n",
      "1078/1078 [==============================] - 0s 40us/step - loss: 0.4171 - acc: 0.8414\n",
      "Epoch 41/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 0.4060 - acc: 0.8609\n",
      "Epoch 42/100\n",
      "1078/1078 [==============================] - 0s 40us/step - loss: 0.4009 - acc: 0.8683\n",
      "Epoch 43/100\n",
      "1078/1078 [==============================] - 0s 43us/step - loss: 0.3840 - acc: 0.8692\n",
      "Epoch 44/100\n",
      "1078/1078 [==============================] - 0s 40us/step - loss: 0.3713 - acc: 0.8831\n",
      "Epoch 45/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 0.3699 - acc: 0.8748\n",
      "Epoch 46/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 0.3591 - acc: 0.8729\n",
      "Epoch 47/100\n",
      "1078/1078 [==============================] - 0s 41us/step - loss: 0.3545 - acc: 0.8776\n",
      "Epoch 48/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 0.3594 - acc: 0.8738\n",
      "Epoch 49/100\n",
      "1078/1078 [==============================] - 0s 40us/step - loss: 0.3371 - acc: 0.8878\n",
      "Epoch 50/100\n",
      "1078/1078 [==============================] - 0s 40us/step - loss: 0.3343 - acc: 0.8887\n",
      "Epoch 51/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 0.3282 - acc: 0.8859\n",
      "Epoch 52/100\n",
      "1078/1078 [==============================] - 0s 40us/step - loss: 0.3323 - acc: 0.8822\n",
      "Epoch 53/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.3010 - acc: 0.8989\n",
      "Epoch 54/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.3126 - acc: 0.8961\n",
      "Epoch 55/100\n",
      "1078/1078 [==============================] - 0s 38us/step - loss: 0.2953 - acc: 0.9026\n",
      "Epoch 56/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.2877 - acc: 0.9054\n",
      "Epoch 57/100\n",
      "1078/1078 [==============================] - 0s 38us/step - loss: 0.2644 - acc: 0.9212\n",
      "Epoch 58/100\n",
      "1078/1078 [==============================] - 0s 38us/step - loss: 0.2754 - acc: 0.9100\n",
      "Epoch 59/100\n",
      "1078/1078 [==============================] - 0s 38us/step - loss: 0.2616 - acc: 0.9054\n",
      "Epoch 60/100\n",
      "1078/1078 [==============================] - 0s 39us/step - loss: 0.2796 - acc: 0.9072\n",
      "Epoch 61/100\n",
      "1078/1078 [==============================] - 0s 35us/step - loss: 0.2674 - acc: 0.9026\n",
      "Epoch 62/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.2651 - acc: 0.9063\n",
      "Epoch 63/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.2718 - acc: 0.9063\n",
      "Epoch 64/100\n",
      "1078/1078 [==============================] - 0s 38us/step - loss: 0.2534 - acc: 0.9082\n",
      "Epoch 65/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.2252 - acc: 0.9304\n",
      "Epoch 66/100\n",
      "1078/1078 [==============================] - 0s 40us/step - loss: 0.2755 - acc: 0.9100\n",
      "Epoch 67/100\n",
      "1078/1078 [==============================] - 0s 35us/step - loss: 0.2603 - acc: 0.9137\n",
      "Epoch 68/100\n",
      "1078/1078 [==============================] - 0s 35us/step - loss: 0.2438 - acc: 0.9369\n",
      "Epoch 69/100\n",
      "1078/1078 [==============================] - 0s 41us/step - loss: 0.2224 - acc: 0.9360\n",
      "Epoch 70/100\n",
      "1078/1078 [==============================] - 0s 38us/step - loss: 0.2390 - acc: 0.9276\n",
      "Epoch 71/100\n",
      "1078/1078 [==============================] - 0s 36us/step - loss: 0.2350 - acc: 0.9128\n",
      "Epoch 72/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.2338 - acc: 0.9212\n",
      "Epoch 73/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.1949 - acc: 0.9304\n",
      "Epoch 74/100\n",
      "1078/1078 [==============================] - 0s 40us/step - loss: 0.2188 - acc: 0.9323\n",
      "Epoch 75/100\n",
      "1078/1078 [==============================] - 0s 40us/step - loss: 0.2293 - acc: 0.9212\n",
      "Epoch 76/100\n",
      "1078/1078 [==============================] - 0s 35us/step - loss: 0.2052 - acc: 0.9314\n",
      "Epoch 77/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.1765 - acc: 0.9527\n",
      "Epoch 78/100\n",
      "1078/1078 [==============================] - 0s 41us/step - loss: 0.1855 - acc: 0.9406\n",
      "Epoch 79/100\n",
      "1078/1078 [==============================] - 0s 38us/step - loss: 0.1816 - acc: 0.9434\n",
      "Epoch 80/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.2040 - acc: 0.9276\n",
      "Epoch 81/100\n",
      "1078/1078 [==============================] - 0s 33us/step - loss: 0.2116 - acc: 0.9230\n",
      "Epoch 82/100\n",
      "1078/1078 [==============================] - 0s 35us/step - loss: 0.2016 - acc: 0.9341\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1078/1078 [==============================] - 0s 35us/step - loss: 0.1692 - acc: 0.9425\n",
      "Epoch 84/100\n",
      "1078/1078 [==============================] - 0s 32us/step - loss: 0.1833 - acc: 0.9425\n",
      "Epoch 85/100\n",
      "1078/1078 [==============================] - 0s 34us/step - loss: 0.1744 - acc: 0.9416\n",
      "Epoch 86/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.1555 - acc: 0.9518\n",
      "Epoch 87/100\n",
      "1078/1078 [==============================] - 0s 34us/step - loss: 0.1710 - acc: 0.9416\n",
      "Epoch 88/100\n",
      "1078/1078 [==============================] - 0s 36us/step - loss: 0.1825 - acc: 0.9434\n",
      "Epoch 89/100\n",
      "1078/1078 [==============================] - 0s 36us/step - loss: 0.1658 - acc: 0.9490\n",
      "Epoch 90/100\n",
      "1078/1078 [==============================] - 0s 35us/step - loss: 0.1653 - acc: 0.9471\n",
      "Epoch 91/100\n",
      "1078/1078 [==============================] - 0s 36us/step - loss: 0.1499 - acc: 0.9490\n",
      "Epoch 92/100\n",
      "1078/1078 [==============================] - ETA: 0s - loss: 0.3242 - acc: 0.898 - 0s 35us/step - loss: 0.1787 - acc: 0.9471\n",
      "Epoch 93/100\n",
      "1078/1078 [==============================] - ETA: 0s - loss: 0.1627 - acc: 0.953 - 0s 34us/step - loss: 0.1448 - acc: 0.9592\n",
      "Epoch 94/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.1684 - acc: 0.9416\n",
      "Epoch 95/100\n",
      "1078/1078 [==============================] - 0s 34us/step - loss: 0.1655 - acc: 0.9471\n",
      "Epoch 96/100\n",
      "1078/1078 [==============================] - 0s 35us/step - loss: 0.1598 - acc: 0.9499\n",
      "Epoch 97/100\n",
      "1078/1078 [==============================] - 0s 38us/step - loss: 0.1554 - acc: 0.9518\n",
      "Epoch 98/100\n",
      "1078/1078 [==============================] - 0s 37us/step - loss: 0.1287 - acc: 0.9592\n",
      "Epoch 99/100\n",
      "1078/1078 [==============================] - 0s 38us/step - loss: 0.1580 - acc: 0.9434\n",
      "Epoch 100/100\n",
      "1078/1078 [==============================] - 0s 34us/step - loss: 0.1328 - acc: 0.9508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd2b78705f8>"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units=25,activation='relu',kernel_initializer='uniform',input_dim=64))\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "classifier.add(Dense(units=20,activation='relu',kernel_initializer='uniform'))\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "classifier.add(Dense(units=15,activation='relu',kernel_initializer='uniform'))\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "classifier.add(Dense(units=10,activation='softmax',kernel_initializer='uniform'))\n",
    "\n",
    "#opt = optimizers.SGD(lr=0.01)\n",
    "classifier.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "classifier.fit(x_train,y_train,batch_size=128,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.01121675e-22,   1.68660499e-05,   9.98898029e-01, ...,\n",
       "          7.56982810e-10,   1.48520019e-04,   2.78931587e-12],\n",
       "       [  3.29152073e-07,   6.60946639e-03,   6.90535700e-04, ...,\n",
       "          9.86643869e-08,   9.84872460e-01,   7.85536395e-06],\n",
       "       [  4.75113481e-32,   1.56001491e-07,   9.99951005e-01, ...,\n",
       "          1.51219816e-13,   2.23319194e-06,   4.29581461e-17],\n",
       "       ..., \n",
       "       [  1.22173260e-33,   1.26867130e-08,   9.99919891e-01, ...,\n",
       "          1.17660864e-14,   1.74828699e-06,   7.99159621e-18],\n",
       "       [  2.62623213e-12,   2.12424711e-05,   2.55693844e-09, ...,\n",
       "          9.99907613e-01,   4.55322141e-13,   6.36717377e-05],\n",
       "       [  5.63100584e-05,   5.20995930e-02,   9.73275900e-02, ...,\n",
       "          1.87300018e-03,   7.50050485e-01,   9.50804725e-03]], dtype=float32)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual output : 4\n",
      "Predicted Output output : 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd2b8cc8160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd = np.random.randint(0,len(y_test))\n",
    "print('Actual output :' , y_temp_test[rnd][0])\n",
    "max_index, max_value = max(enumerate(y_pred[rnd]), key=operator.itemgetter(1))\n",
    "print('Predicted Output output :' , max_index)\n",
    "data = x_temp_test[rnd].reshape((8,8))\n",
    "plt.imshow(255-data)\n",
    "plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
